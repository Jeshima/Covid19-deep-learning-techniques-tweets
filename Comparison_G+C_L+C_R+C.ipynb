{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparison_G+C_L+C_R+C.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqfyzMW_oRSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D,SpatialDropout1D,GRU,LSTM\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from keras.layers import LSTM,GRU,SimpleRNN\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "import pandas as pd\n",
        "from termcolor import colored\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb0kFyZxoVM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cee8577-e9c8-4f57-d57d-d4ced337ad37"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE5PUbhcopUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "88199184-b8b7-4c93-9f7f-83ea5fce3f1c"
      },
      "source": [
        "\n",
        "# Import twitter data\n",
        "print(colored(\"Loading train and test data\", \"green\"))\n",
        "\n",
        "tr = pd.read_csv(\"/content/drive/My Drive/big.csv\")\n",
        "te = pd.read_csv(\"/content/drive/My Drive/twt_#ifc.csv\")\n",
        "\n",
        "tr.full_text=tr.full_text.astype(str)\n",
        "te.full_text=te.full_text.astype(str)\n",
        "print(colored(\"... \\nData loaded\", \"green\"))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mLoading train and test data\u001b[0m\n",
            "\u001b[32m... \n",
            "Data loaded\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLUG5irVp_BU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2d7b747c-e865-4cb1-ca4d-f2fa195c33d8"
      },
      "source": [
        "\n",
        "# Tokenization\n",
        "print(colored(\"Tokenizing and padding data\", \"green\"))\n",
        "tokenizer = Tokenizer(num_words = 2000, split = ' ')\n",
        "tokenizer.fit_on_texts(tr['full_text'].astype(str).values)\n",
        "train_tweets = tokenizer.texts_to_sequences(tr['full_text'].astype(str).values)\n",
        "max_len = max([len(i) for i in train_tweets])\n",
        "train_tweets = pad_sequences(train_tweets, maxlen = max_len)\n",
        "test_tweets = tokenizer.texts_to_sequences(te['full_text'].astype(str).values)\n",
        "test_tweets = pad_sequences(test_tweets, maxlen = max_len)\n",
        "print(colored(\"Tokenizing and padding complete\", \"yellow\"))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTokenizing and padding data\u001b[0m\n",
            "\u001b[33mTokenizing and padding complete\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE3qj1NYqe2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "c93d0616-6650-4c6b-e215-e1ae6b053dd5"
      },
      "source": [
        "# Building the model\n",
        "print(colored(\"Creating the GRU + CNN model\", \"yellow\"))\n",
        "modelgcnn = Sequential()\n",
        "modelgcnn.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "modelgcnn.add(SpatialDropout1D(0.4))\n",
        "modelgcnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(8, 1)))\n",
        "modelgcnn.add(MaxPooling1D(pool_length=(2)))\n",
        "modelgcnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(8, 1)))\n",
        "modelgcnn.add(GRU(128))\n",
        "\n",
        "\n",
        "modelgcnn.add(Dense(3, activation = 'softmax'))\n",
        "modelgcnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelgcnn.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the GRU + CNN model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(8, 1), padding=\"same\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(8, 1), padding=\"same\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_10 (Spatia (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 37, 64)            24640     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 18, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 18, 64)            12352     \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (None, 128)               74112     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 367,491\n",
            "Trainable params: 367,491\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw1UPOcoqvYB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c1e5148c-4968-4dff-a3d6-8651708ce36e"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the GRU + CNN model\", \"green\"))\n",
        "history = modelgcnn.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the GRU + CNN model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 17s 831us/step - loss: 0.8062 - accuracy: 0.6071\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 17s 809us/step - loss: 0.5847 - accuracy: 0.7496\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 17s 805us/step - loss: 0.5219 - accuracy: 0.7851\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7f7a99876e80>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7loW8hFq1jK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f0937e67-6e42-4a6e-a7b3-467d481aecc9"
      },
      "source": [
        " print(colored(\"Testing the GRU + CNN model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelgcnn.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x1=accuracy\n",
        "score, accuracy = modelgcnn.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "\n",
        "y1=accuracy"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the GRU + CNN model\u001b[0m\n",
            "20741/20741 [==============================] - 4s 188us/step\n",
            "\u001b[33mTrain accuracy: 0.8348681330680847\u001b[0m\n",
            "1749/1749 [==============================] - 0s 182us/step\n",
            "\u001b[33mTest accuracy: 0.7930245995521545\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NeYQmbm3ByH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "46f0b3f9-de39-46ff-a5eb-42430f1b3f06"
      },
      "source": [
        "# Building the model\n",
        "print(colored(\"Creating the LSTM + CNN model\", \"yellow\"))\n",
        "modelcnnl = Sequential()\n",
        "modelcnnl.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "modelcnnl.add(SpatialDropout1D(0.4))\n",
        "modelcnnl.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(8, 1)))\n",
        "modelcnnl.add(MaxPooling1D(pool_length=(2)))\n",
        "modelcnnl.add(LSTM(128))\n",
        "\n",
        "modelcnnl.add(Dense(3, activation = 'softmax'))\n",
        "modelcnnl.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelcnnl.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the LSTM + CNN model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(8, 1), padding=\"same\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_12 (Spatia (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 37, 64)            24640     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 18, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 379,843\n",
            "Trainable params: 379,843\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-IvoV504K7U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4aaa0383-372f-4edf-c6e1-28b9a80b1bd1"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the LSTM + CNN model\", \"green\"))\n",
        "history = modelcnnl.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the LSTM + CNN model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 17s 812us/step - loss: 0.8106 - accuracy: 0.6069\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 16s 765us/step - loss: 0.5911 - accuracy: 0.7463\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 16s 769us/step - loss: 0.5291 - accuracy: 0.7775\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7f7a995c54a8>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHhTa2Wv7WTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e428786c-ce7f-4325-dd48-9a01b81de4da"
      },
      "source": [
        " print(colored(\"Testing the LSTM + CNN model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelcnnl.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x2=accuracy\n",
        "score, accuracy = modelcnnl.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y2=accuracy"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the LSTM + CNN model\u001b[0m\n",
            "20741/20741 [==============================] - 4s 203us/step\n",
            "\u001b[33mTrain accuracy: 0.8182344436645508\u001b[0m\n",
            "1749/1749 [==============================] - 0s 192us/step\n",
            "\u001b[33mTest accuracy: 0.7901657819747925\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIebq57I8Vvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "41199a90-647d-4572-9a52-0b56cd606ca0"
      },
      "source": [
        "# Building the model\n",
        "print(colored(\"Creating the RNN + CNN model\", \"yellow\"))\n",
        "modelrcnn = Sequential()\n",
        "modelrcnn.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "modelrcnn.add(SpatialDropout1D(0.4))\n",
        "modelrcnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(8, 1)))\n",
        "modelrcnn.add(MaxPooling1D(pool_length=(2)))\n",
        "modelrcnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(8, 1)))\n",
        "\n",
        "modelrcnn.add(SimpleRNN(128))\n",
        "\n",
        "modelrcnn.add(Dense(3, activation = 'softmax'))\n",
        "modelrcnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelrcnn.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the RNN + CNN model\u001b[0m\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_14 (Spatia (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 37, 64)            24640     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling (None, 18, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 18, 64)            12352     \n",
            "_________________________________________________________________\n",
            "simple_rnn_13 (SimpleRNN)    (None, 128)               24704     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 318,083\n",
            "Trainable params: 318,083\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(8, 1), padding=\"same\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(8, 1), padding=\"same\")`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYpKQOBi8VnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "aa000e11-d8e1-485d-b474-8b71dd13b374"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the RNN + CNN model\", \"green\"))\n",
        "history = modelrcnn.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the RNN + CNN model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 9s 435us/step - loss: 0.8238 - accuracy: 0.5956\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 9s 421us/step - loss: 0.5974 - accuracy: 0.7405\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 9s 419us/step - loss: 0.5029 - accuracy: 0.7939\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7f7a9a2c8a90>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojxtPXno8Vf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b1fee9ab-b363-4f58-fa12-2d2103a3ab8a"
      },
      "source": [
        " print(colored(\"Testing the RNN + CNN model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelrcnn.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x=accuracy\n",
        "score, accuracy = modelrcnn.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y=accuracy"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the RNN + CNN model\u001b[0m\n",
            "20741/20741 [==============================] - 2s 113us/step\n",
            "\u001b[33mTrain accuracy: 0.8630731105804443\u001b[0m\n",
            "1749/1749 [==============================] - 0s 113us/step\n",
            "\u001b[33mTest accuracy: 0.802744448184967\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG6BtAhP7kVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tabulate import tabulate\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeGL5dP17wE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3e4d06ea-7b7f-40e1-a3ab-1d03e21266d7"
      },
      "source": [
        "\n",
        "print(tabulate([\n",
        "    ['RNN + CNN',x,y], \n",
        "    ['GRU + CNN',x1,y1],\n",
        "    ['LSTM + CNN',x2,y2]], \n",
        "    \n",
        "    headers=['Model', 'Training Accuracy','Testing Accuracy']))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model         Training Accuracy    Testing Accuracy\n",
            "----------  -------------------  ------------------\n",
            "RNN + CNN              0.863073            0.802744\n",
            "GRU + CNN              0.834868            0.793025\n",
            "LSTM + CNN             0.818234            0.790166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nj0GG9z751C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}