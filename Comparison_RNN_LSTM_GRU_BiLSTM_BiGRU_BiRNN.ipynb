{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparison_RNN-LSTM-GRU-BiLSTM-BiGRU-BiRNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqfyzMW_oRSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, Bidirectional,GRU,SpatialDropout1D,SimpleRNN\n",
        "from keras.datasets import imdb\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import (precision_score, recall_score,\n",
        "                             f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import h5py\n",
        "from keras import callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb0kFyZxoVM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfd39e4c-bf02-47b0-9fe7-8b1781561638"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE5PUbhcopUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e39eb909-8852-4d6a-ad9b-afaf34a44731"
      },
      "source": [
        "\n",
        "# Import twitter data\n",
        "print(colored(\"Loading train and test data\", \"green\"))\n",
        "\n",
        "tr = pd.read_csv(\"/content/drive/My Drive/big.csv\")\n",
        "te = pd.read_csv(\"/content/drive/My Drive/twt_#ifc.csv\")\n",
        "\n",
        "tr.full_text=tr.full_text.astype(str)\n",
        "te.full_text=te.full_text.astype(str)\n",
        "print(colored(\"... \\nData loaded\", \"green\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mLoading train and test data\u001b[0m\n",
            "\u001b[32m... \n",
            "Data loaded\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzRF1JVKIB2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73ad3fcd-36c7-4317-a1b7-12672c5c95e3"
      },
      "source": [
        "\n",
        "# Tokenization\n",
        "print(colored(\"Tokenizing and padding data\", \"green\"))\n",
        "tokenizer = Tokenizer(num_words = 2000, split = ' ')\n",
        "tokenizer.fit_on_texts(tr['full_text'].astype(str).values)\n",
        "train_tweets = tokenizer.texts_to_sequences(tr['full_text'].astype(str).values)\n",
        "max_len = max([len(i) for i in train_tweets])\n",
        "train_tweets = pad_sequences(train_tweets, maxlen = max_len)\n",
        "test_tweets = tokenizer.texts_to_sequences(te['full_text'].astype(str).values)\n",
        "test_tweets = pad_sequences(test_tweets, maxlen = max_len)\n",
        "print(colored(\"Tokenizing and padding complete\", \"yellow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTokenizing and padding data\u001b[0m\n",
            "\u001b[33mTokenizing and padding complete\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEyCBf99fpPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9010f0b9-4122-4005-f6f1-44acc6d204fb"
      },
      "source": [
        "print(colored(\"Creating the Bidirectional SimpleRNN model\", \"yellow\"))\n",
        "\n",
        "modelbrnn = Sequential()\n",
        "modelbrnn.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "\n",
        "modelbrnn.add(Bidirectional(SimpleRNN(128)))\n",
        "\n",
        "modelbrnn.add(Dropout(0.1))\n",
        "\n",
        "modelbrnn.add(Dense(3, activation = 'softmax'))\n",
        "modelbrnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelbrnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the Bidirectional SimpleRNN model\u001b[0m\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_34 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "bidirectional_25 (Bidirectio (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 322,563\n",
            "Trainable params: 322,563\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkql0plsfpFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "43ef7158-7093-4266-8071-d377179b2313"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the Bidirectional SimpleRNN model\", \"green\"))\n",
        "history = modelbrnn.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the Bidirectional SimpleRNN model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 12s 569us/step - loss: 0.8776 - accuracy: 0.5681\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 11s 549us/step - loss: 0.6329 - accuracy: 0.7270\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 11s 545us/step - loss: 0.4359 - accuracy: 0.8240\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa7282a400>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KVe-JsGfo1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "db26e209-066c-450b-cf53-0a837d48d07d"
      },
      "source": [
        "print(colored(\"Testing the Bidirectional SimpleRNNmodel\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelbrnn.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x5=accuracy\n",
        "score, accuracy = modelbrnn.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y5=accuracy\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the Bidirectional SimpleRNNmodel\u001b[0m\n",
            "20741/20741 [==============================] - 3s 167us/step\n",
            "\u001b[33mTrain accuracy: 0.9244973659515381\u001b[0m\n",
            "1749/1749 [==============================] - 0s 161us/step\n",
            "\u001b[33mTest accuracy: 0.8393367528915405\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfeXjFJpMJ7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "f880bf96-632e-4735-a161-58012b9baf50"
      },
      "source": [
        "\n",
        "# Building the model\n",
        "print(colored(\"Creating the LSTM model\", \"yellow\"))\n",
        "modellstm = Sequential()\n",
        "modellstm.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "modellstm.add(SpatialDropout1D(0.4))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = False))\n",
        "\n",
        "modellstm.add(Dense(3, activation = 'softmax'))\n",
        "modellstm.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modellstm.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the LSTM model\u001b[0m\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_35 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_9 (Spatial (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_27 (LSTM)               (None, 37, 256)           394240    \n",
            "_________________________________________________________________\n",
            "lstm_28 (LSTM)               (None, 37, 256)           525312    \n",
            "_________________________________________________________________\n",
            "lstm_29 (LSTM)               (None, 37, 256)           525312    \n",
            "_________________________________________________________________\n",
            "lstm_30 (LSTM)               (None, 37, 256)           525312    \n",
            "_________________________________________________________________\n",
            "lstm_31 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 2,752,259\n",
            "Trainable params: 2,752,259\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSHVq9FPMMSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ba61c756-cdbf-48d4-8f7d-c8733d856a17"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the LSTM model\", \"green\"))\n",
        "history = modellstm.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the LSTM model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 357s 17ms/step - loss: 0.9264 - accuracy: 0.5343\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 355s 17ms/step - loss: 0.7882 - accuracy: 0.6215\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 350s 17ms/step - loss: 0.6686 - accuracy: 0.7083\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa6179e7b8>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "147_0_nMMSJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "59b9e70b-2e8c-41c9-97b9-04f2ef94215f"
      },
      "source": [
        "print(colored(\"Testing the LSTM model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modellstm.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x=accuracy\n",
        "score, accuracy = modellstm.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y=accuracy\n"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the LSTM model\u001b[0m\n",
            "20741/20741 [==============================] - 97s 5ms/step\n",
            "\u001b[33mTrain accuracy: 0.7723349928855896\u001b[0m\n",
            "1749/1749 [==============================] - 8s 5ms/step\n",
            "\u001b[33mTest accuracy: 0.739279568195343\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEnGxCG3MZRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "bd3b0aca-08e9-44b5-e5fe-fec74ed0735c"
      },
      "source": [
        "# Building the model\n",
        "print(colored(\"Creating the GRU model\", \"yellow\"))\n",
        "modelgru = Sequential()\n",
        "modelgru.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "modelgru.add(SpatialDropout1D(0.4))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = False))\n",
        "\n",
        "modelgru.add(Dense(3, activation = 'softmax'))\n",
        "modelgru.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelgru.summary()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the GRU model\u001b[0m\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_36 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_10 (Spatia (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "gru_9 (GRU)                  (None, 37, 256)           295680    \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (None, 37, 256)           393984    \n",
            "_________________________________________________________________\n",
            "gru_11 (GRU)                 (None, 37, 256)           393984    \n",
            "_________________________________________________________________\n",
            "gru_12 (GRU)                 (None, 37, 256)           393984    \n",
            "_________________________________________________________________\n",
            "gru_13 (GRU)                 (None, 256)               393984    \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 2,128,387\n",
            "Trainable params: 2,128,387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGcJPxSTMinY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "cf9d79b3-004b-49e6-ffbe-e0eb7c6d89f4"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the GRU model\", \"green\"))\n",
        "history = modelgru.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the GRU model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 365s 18ms/step - loss: 2636827.3462 - accuracy: 0.4218\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 360s 17ms/step - loss: 203727.9804 - accuracy: 0.4258\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 355s 17ms/step - loss: 64065.1102 - accuracy: 0.4202\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa626d9208>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thdK4W1vMmL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "00f45ca4-5a3d-49de-fbbf-e16a879f021e"
      },
      "source": [
        "print(colored(\"Testing the GRU model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelgru.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x1=accuracy\n",
        "score, accuracy = modelgru.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y1=accuracy"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the GRU model\u001b[0m\n",
            "20741/20741 [==============================] - 80s 4ms/step\n",
            "\u001b[33mTrain accuracy: 0.5352200865745544\u001b[0m\n",
            "1749/1749 [==============================] - 7s 4ms/step\n",
            "\u001b[33mTest accuracy: 0.5397369861602783\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QutPRrZa_r7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b7ebd863-8c08-4d78-8ea3-a85646e71e6b"
      },
      "source": [
        "# 1. define the network\n",
        "print(colored(\"Creating the Bidirectional LSTM model\", \"yellow\"))\n",
        "\n",
        "modelblstm = Sequential()\n",
        "modelblstm.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "\n",
        "modelblstm.add(Bidirectional(LSTM(128)))\n",
        "\n",
        "modelblstm.add(Dropout(0.1))\n",
        "\n",
        "modelblstm.add(Dense(3, activation = 'softmax'))\n",
        "modelblstm.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelblstm.summary()"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the Bidirectional LSTM model\u001b[0m\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_37 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "bidirectional_26 (Bidirectio (None, 256)               263168    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 519,939\n",
            "Trainable params: 519,939\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_j3EDIlIO23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f6b4e4eb-7fd6-4f61-c4f9-9946ad52693a"
      },
      "source": [
        "\n",
        "# Training the model\n",
        "print(colored(\"Training the Bidirectional LSTM model\", \"green\"))\n",
        "history = modelblstm.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the Bidirectional LSTM model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 53s 3ms/step - loss: 0.7831 - accuracy: 0.6305\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 52s 3ms/step - loss: 0.5693 - accuracy: 0.7512\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 51s 2ms/step - loss: 0.5204 - accuracy: 0.7814\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa606d7b70>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAKpF_EuAqP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "69fdd1a9-c004-4799-dc91-67f1a7dbe72a"
      },
      "source": [
        "\n",
        "print(colored(\"Testing the Bidirectional LSTM model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelblstm.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x2=accuracy\n",
        "score, accuracy = modelblstm.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y2=accuracy"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the Bidirectional LSTM model\u001b[0m\n",
            "20741/20741 [==============================] - 14s 653us/step\n",
            "\u001b[33mTrain accuracy: 0.8148594498634338\u001b[0m\n",
            "1749/1749 [==============================] - 1s 653us/step\n",
            "\u001b[33mTest accuracy: 0.7821612358093262\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8QWAq0SKC6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e7a39b3f-5435-47a5-d9ae-bf7546ff6d3f"
      },
      "source": [
        "# 1. define the network\n",
        "print(colored(\"Creating the Bidirectional GRU model\", \"yellow\"))\n",
        "\n",
        "modelbgru = Sequential()\n",
        "modelbgru.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "\n",
        "modelbgru.add(Bidirectional(GRU(128)))\n",
        "\n",
        "modelbgru.add(Dropout(0.1))\n",
        "\n",
        "modelbgru.add(Dense(3, activation = 'softmax'))\n",
        "modelbgru.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelbgru.summary()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the Bidirectional GRU model\u001b[0m\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_38 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "bidirectional_27 (Bidirectio (None, 256)               197376    \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 454,147\n",
            "Trainable params: 454,147\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqWPt7LkKvZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "7636aec9-4d22-41f6-8744-751842a7d280"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the Bidirectional GRU model\", \"green\"))\n",
        "history = modelbgru.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the Bidirectional GRU model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 53s 3ms/step - loss: 0.7799 - accuracy: 0.6291\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 52s 2ms/step - loss: 0.5655 - accuracy: 0.7573\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 52s 2ms/step - loss: 0.5198 - accuracy: 0.7788\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa6332cef0>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sHn7PhvLtX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a536326a-2f7a-435f-c318-bf1df19ada20"
      },
      "source": [
        "\n",
        "print(colored(\"Testing the Bidirectional GRU  model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelbgru.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x3=accuracy\n",
        "score, accuracy = modelbgru.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y3=accuracy"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the Bidirectional GRU  model\u001b[0m\n",
            "20741/20741 [==============================] - 12s 564us/step\n",
            "\u001b[33mTrain accuracy: 0.816257655620575\u001b[0m\n",
            "1749/1749 [==============================] - 1s 559us/step\n",
            "\u001b[33mTest accuracy: 0.7827329635620117\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEWyX-HNL7_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "2c3c6210-68eb-40c0-974f-883a8d5b29a8"
      },
      "source": [
        "# Building the model\n",
        "print(colored(\"Creating the Vanilla RNN model\", \"yellow\"))\n",
        "modelvrnn = Sequential()\n",
        "modelvrnn.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "modelvrnn.add(SpatialDropout1D(0.4))\n",
        "modelvrnn.add(SimpleRNN(256,return_sequences = True))\n",
        "modelvrnn.add(SimpleRNN(256,return_sequences = False))\n",
        "\n",
        "modelvrnn.add(Dense(3, activation = 'softmax'))\n",
        "modelvrnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelvrnn.summary()"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the Vanilla RNN model\u001b[0m\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_39 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_11 (Spatia (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_5 (SimpleRNN)     (None, 37, 256)           98560     \n",
            "_________________________________________________________________\n",
            "simple_rnn_6 (SimpleRNN)     (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 486,659\n",
            "Trainable params: 486,659\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax8MwqkAQIjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "01bf8471-01ba-4133-ece3-6fe33cb9253f"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the Vanilla RNN model\", \"green\"))\n",
        "history = modelvrnn.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the Vanilla RNN model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 35s 2ms/step - loss: 0.9458 - accuracy: 0.5186\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 34s 2ms/step - loss: 0.7946 - accuracy: 0.6194\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 34s 2ms/step - loss: 0.6243 - accuracy: 0.7333\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa63a3c9e8>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH96K0XLQL3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b77c3017-3268-4b20-f943-886c817e3e88"
      },
      "source": [
        "print(colored(\"Testing the Vanilla RNN model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelvrnn.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x4=accuracy\n",
        "score, accuracy = modelvrnn.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y4=accuracy"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the Vanilla RNN model\u001b[0m\n",
            "20741/20741 [==============================] - 11s 548us/step\n",
            "\u001b[33mTrain accuracy: 0.8334217071533203\u001b[0m\n",
            "1749/1749 [==============================] - 1s 552us/step\n",
            "\u001b[33mTest accuracy: 0.7873070240020752\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5vcSwzLaQcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tabulate import tabulate\n"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZt_fvMLEXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "847f42ac-889b-4dce-950c-814375ca594b"
      },
      "source": [
        "print(tabulate([\n",
        "    ['LSTM',x,y], \n",
        "    ['GRU',x1,y1],\n",
        "    ['Bi-LSTM',x2,y2],\n",
        "    ['Bi-GRU',x3,y3],\n",
        "    ['SimpleRNN/V-RNN',x4,y4],\n",
        "    ['Bi-SimpleRNN',x5,y5]], \n",
        "    \n",
        "    headers=['Model', 'Training Accuracy','Testing Accuracy']))"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model              Training Accuracy    Testing Accuracy\n",
            "---------------  -------------------  ------------------\n",
            "LSTM                        0.772335            0.73928\n",
            "GRU                         0.53522             0.539737\n",
            "Bi-LSTM                     0.814859            0.782161\n",
            "Bi-GRU                      0.816258            0.782733\n",
            "SimpleRNN/V-RNN             0.833422            0.787307\n",
            "Bi-SimpleRNN                0.924497            0.839337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejors6dqaG6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}