{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparison_RNN-LSTM-GRU-Bi-LSTM-Bi-GRU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqfyzMW_oRSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, Bidirectional,GRU,SpatialDropout1D,SimpleRNN\n",
        "from keras.datasets import imdb\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import (precision_score, recall_score,\n",
        "                             f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import h5py\n",
        "from keras import callbacks"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb0kFyZxoVM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73a72393-38ac-4391-df77-5ba0dbc0239f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE5PUbhcopUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0a39dd83-f5b6-4ecc-c9e3-170e0227948d"
      },
      "source": [
        "\n",
        "# Import twitter data\n",
        "print(colored(\"Loading train and test data\", \"green\"))\n",
        "\n",
        "tr = pd.read_csv(\"/content/drive/My Drive/big.csv\")\n",
        "te = pd.read_csv(\"/content/drive/My Drive/twt_#ifc.csv\")\n",
        "\n",
        "tr.full_text=tr.full_text.astype(str)\n",
        "te.full_text=te.full_text.astype(str)\n",
        "print(colored(\"... \\nData loaded\", \"green\"))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mLoading train and test data\u001b[0m\n",
            "\u001b[32m... \n",
            "Data loaded\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzRF1JVKIB2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "93ee6f23-5fcb-457a-ca29-7382991259d4"
      },
      "source": [
        "\n",
        "# Tokenization\n",
        "print(colored(\"Tokenizing and padding data\", \"green\"))\n",
        "tokenizer = Tokenizer(num_words = 2000, split = ' ')\n",
        "tokenizer.fit_on_texts(tr['full_text'].astype(str).values)\n",
        "train_tweets = tokenizer.texts_to_sequences(tr['full_text'].astype(str).values)\n",
        "max_len = max([len(i) for i in train_tweets])\n",
        "train_tweets = pad_sequences(train_tweets, maxlen = max_len)\n",
        "test_tweets = tokenizer.texts_to_sequences(te['full_text'].astype(str).values)\n",
        "test_tweets = pad_sequences(test_tweets, maxlen = max_len)\n",
        "print(colored(\"Tokenizing and padding complete\", \"yellow\"))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTokenizing and padding data\u001b[0m\n",
            "\u001b[33mTokenizing and padding complete\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfeXjFJpMJ7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "611fa4ae-e64a-46e2-8bcd-91f93ce4988d"
      },
      "source": [
        "\n",
        "# Building the model\n",
        "print(colored(\"Creating the LSTM model\", \"yellow\"))\n",
        "modellstm = Sequential()\n",
        "modellstm.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "modellstm.add(SpatialDropout1D(0.4))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modellstm.add(LSTM(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = False))\n",
        "\n",
        "modellstm.add(Dense(3, activation = 'softmax'))\n",
        "modellstm.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modellstm.summary()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the LSTM model\u001b[0m\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_28 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_6 (Spatial (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 37, 256)           394240    \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 37, 256)           525312    \n",
            "_________________________________________________________________\n",
            "lstm_23 (LSTM)               (None, 37, 256)           525312    \n",
            "_________________________________________________________________\n",
            "lstm_24 (LSTM)               (None, 37, 256)           525312    \n",
            "_________________________________________________________________\n",
            "lstm_25 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 2,752,259\n",
            "Trainable params: 2,752,259\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSHVq9FPMMSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "09f22b76-cb14-45e6-cdb2-757aed1e1c3c"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the LSTM model\", \"green\"))\n",
        "history = modellstm.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the LSTM model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 340s 16ms/step - loss: 0.9195 - accuracy: 0.5401\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 342s 17ms/step - loss: 0.7819 - accuracy: 0.6262\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 340s 16ms/step - loss: 0.6666 - accuracy: 0.7109\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa65c01a20>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "147_0_nMMSJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "343e72c6-f0d4-459f-eb78-86c8b087a038"
      },
      "source": [
        "print(colored(\"Testing the LSTM model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modellstm.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x=accuracy\n",
        "score, accuracy = modellstm.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y=accuracy\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the LSTM model\u001b[0m\n",
            "20741/20741 [==============================] - 95s 5ms/step\n",
            "\u001b[33mTrain accuracy: 0.7634636759757996\u001b[0m\n",
            "1749/1749 [==============================] - 8s 5ms/step\n",
            "\u001b[33mTest accuracy: 0.7364208102226257\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEnGxCG3MZRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "f36c1f33-4943-4562-cabd-f3c4a8ab90ea"
      },
      "source": [
        "# Building the model\n",
        "print(colored(\"Creating the GRU model\", \"yellow\"))\n",
        "modelgru = Sequential()\n",
        "modelgru.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "modelgru.add(SpatialDropout1D(0.4))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = True))\n",
        "modelgru.add(GRU(256, dropout = 0.2,recurrent_dropout = 0.5,return_sequences = False))\n",
        "\n",
        "modelgru.add(Dense(3, activation = 'softmax'))\n",
        "modelgru.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelgru.summary()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the GRU model\u001b[0m\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_29 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_7 (Spatial (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 37, 256)           295680    \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 37, 256)           393984    \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (None, 37, 256)           393984    \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (None, 37, 256)           393984    \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (None, 256)               393984    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 2,128,387\n",
            "Trainable params: 2,128,387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGcJPxSTMinY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "0acf9dbe-ea95-4911-f6c9-c0501d963657"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the GRU model\", \"green\"))\n",
        "history = modelgru.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the GRU model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 351s 17ms/step - loss: 1407594.0326 - accuracy: 0.4251\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 349s 17ms/step - loss: 103313.9306 - accuracy: 0.4197\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 350s 17ms/step - loss: 409289.6453 - accuracy: 0.4232\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa7a6543c8>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thdK4W1vMmL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "acc152d6-7585-4d4d-d177-e57e209eb07d"
      },
      "source": [
        "print(colored(\"Testing the GRU model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelgru.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x1=accuracy\n",
        "score, accuracy = modelgru.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y1=accuracy"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the GRU model\u001b[0m\n",
            "20741/20741 [==============================] - 79s 4ms/step\n",
            "\u001b[33mTrain accuracy: 0.5352200865745544\u001b[0m\n",
            "1749/1749 [==============================] - 7s 4ms/step\n",
            "\u001b[33mTest accuracy: 0.5397369861602783\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QutPRrZa_r7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "767f1022-6a09-4676-a8b3-5d382d7d2935"
      },
      "source": [
        "# 1. define the network\n",
        "print(colored(\"Creating the Bidirectional LSTM model\", \"yellow\"))\n",
        "\n",
        "modelblstm = Sequential()\n",
        "modelblstm.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "\n",
        "modelblstm.add(Bidirectional(LSTM(128)))\n",
        "\n",
        "modelblstm.add(Dropout(0.1))\n",
        "\n",
        "modelblstm.add(Dense(3, activation = 'softmax'))\n",
        "modelblstm.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelblstm.summary()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the Bidirectional LSTM model\u001b[0m\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_30 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "bidirectional_22 (Bidirectio (None, 256)               263168    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 519,939\n",
            "Trainable params: 519,939\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_j3EDIlIO23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "d9700421-2f91-48c0-963e-c85c3ddae1d7"
      },
      "source": [
        "\n",
        "# Training the model\n",
        "print(colored(\"Training the Bidirectional LSTM model\", \"green\"))\n",
        "history = modelblstm.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the Bidirectional LSTM model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 52s 3ms/step - loss: 0.7936 - accuracy: 0.6223\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 51s 2ms/step - loss: 0.5761 - accuracy: 0.7505\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 51s 2ms/step - loss: 0.5226 - accuracy: 0.7768\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa633a8fd0>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAKpF_EuAqP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2cb7b47d-79c0-4847-ccbd-6efe7e94b044"
      },
      "source": [
        "\n",
        "print(colored(\"Testing the Bidirectional LSTM model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelblstm.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x2=accuracy\n",
        "score, accuracy = modelblstm.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y2=accuracy"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the Bidirectional LSTM model\u001b[0m\n",
            "20741/20741 [==============================] - 13s 650us/step\n",
            "\u001b[33mTrain accuracy: 0.8055059909820557\u001b[0m\n",
            "1749/1749 [==============================] - 1s 666us/step\n",
            "\u001b[33mTest accuracy: 0.7764436602592468\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8QWAq0SKC6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8e77c949-72f0-41d1-c932-920c36f018f7"
      },
      "source": [
        "# 1. define the network\n",
        "print(colored(\"Creating the Bidirectional GRU model\", \"yellow\"))\n",
        "\n",
        "modelbgru = Sequential()\n",
        "modelbgru.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "\n",
        "modelbgru.add(Bidirectional(GRU(128)))\n",
        "\n",
        "modelbgru.add(Dropout(0.1))\n",
        "\n",
        "modelbgru.add(Dense(3, activation = 'softmax'))\n",
        "modelbgru.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelbgru.summary()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the Bidirectional GRU model\u001b[0m\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_31 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "bidirectional_23 (Bidirectio (None, 256)               197376    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 454,147\n",
            "Trainable params: 454,147\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqWPt7LkKvZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "5e023590-4456-4de5-92b5-9dc4b16c96e7"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the Bidirectional GRU model\", \"green\"))\n",
        "history = modelbgru.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the Bidirectional GRU model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 53s 3ms/step - loss: 0.7787 - accuracy: 0.6263\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 52s 2ms/step - loss: 0.5640 - accuracy: 0.7573\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 52s 2ms/step - loss: 0.5220 - accuracy: 0.7778\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa62e2df98>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sHn7PhvLtX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "24946030-c70a-4f99-fac8-95b3849e6eb5"
      },
      "source": [
        "\n",
        "print(colored(\"Testing the Bidirectional GRU  model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelbgru.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x3=accuracy\n",
        "score, accuracy = modelbgru.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y3=accuracy"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the Bidirectional GRU  model\u001b[0m\n",
            "20741/20741 [==============================] - 11s 552us/step\n",
            "\u001b[33mTrain accuracy: 0.8114362955093384\u001b[0m\n",
            "1749/1749 [==============================] - 1s 538us/step\n",
            "\u001b[33mTest accuracy: 0.7810177206993103\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEWyX-HNL7_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "e1fddd5f-becc-443e-d146-33f805d2cc0c"
      },
      "source": [
        "# Building the model\n",
        "print(colored(\"Creating the Vanilla RNN model\", \"yellow\"))\n",
        "modelvrnn = Sequential()\n",
        "modelvrnn.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "modelvrnn.add(SpatialDropout1D(0.4))\n",
        "modelvrnn.add(SimpleRNN(256,return_sequences = True))\n",
        "modelvrnn.add(SimpleRNN(256,return_sequences = False))\n",
        "\n",
        "modelvrnn.add(Dense(3, activation = 'softmax'))\n",
        "modelvrnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "modelvrnn.summary()"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mCreating the Vanilla RNN model\u001b[0m\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_32 (Embedding)     (None, 37, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_8 (Spatial (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 37, 256)           98560     \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 486,659\n",
            "Trainable params: 486,659\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax8MwqkAQIjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "3dc5626a-1beb-42a1-e17d-4266e14ecf2f"
      },
      "source": [
        "# Training the model\n",
        "print(colored(\"Training the Vanilla RNN model\", \"green\"))\n",
        "history = modelvrnn.fit(train_tweets, pd.get_dummies(tr['sent_score']).values, epochs = 3, batch_size = 128)\n",
        "print(colored(history, \"green\"))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTraining the Vanilla RNN model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20741/20741 [==============================] - 35s 2ms/step - loss: 0.9507 - accuracy: 0.5104\n",
            "Epoch 2/3\n",
            "20741/20741 [==============================] - 35s 2ms/step - loss: 0.8106 - accuracy: 0.6154\n",
            "Epoch 3/3\n",
            "20741/20741 [==============================] - 35s 2ms/step - loss: 0.5701 - accuracy: 0.7518\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7ffa62a998d0>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH96K0XLQL3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1ab62adc-d4df-4c0c-c41e-987bbe726ae5"
      },
      "source": [
        "print(colored(\"Testing the Vanilla RNN model\", \"green\"))\n",
        "\n",
        "loss, accuracy = modelvrnn.evaluate(train_tweets, pd.get_dummies(tr['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Train accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "x4=accuracy\n",
        "score, accuracy = modelvrnn.evaluate(test_tweets, pd.get_dummies(te['sent_score']).values, batch_size = 128)\n",
        "print(colored(\"Test accuracy: {}\".format(accuracy),\"yellow\"))\n",
        "y4=accuracy"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTesting the Vanilla RNN model\u001b[0m\n",
            "20741/20741 [==============================] - 11s 532us/step\n",
            "\u001b[33mTrain accuracy: 0.8288414478302002\u001b[0m\n",
            "1749/1749 [==============================] - 1s 539us/step\n",
            "\u001b[33mTest accuracy: 0.7878788113594055\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5vcSwzLaQcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tabulate import tabulate\n"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZt_fvMLEXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9f738937-0b75-4707-f92d-9e7ea1b2bb3a"
      },
      "source": [
        "print(tabulate([\n",
        "    ['LSTM',x,y], \n",
        "    ['GRU',x1,y1],\n",
        "    ['Bi-LSTM',x2,y2],\n",
        "    ['Bi-GRU',x3,y3],\n",
        "    ['V-RNN',x4,y4]], \n",
        "    \n",
        "    headers=['Model', 'Training Accuracy','Testing Accuracy']))"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model      Training Accuracy    Testing Accuracy\n",
            "-------  -------------------  ------------------\n",
            "LSTM                0.763464            0.736421\n",
            "GRU                 0.53522             0.539737\n",
            "Bi-LSTM             0.805506            0.776444\n",
            "Bi-GRU              0.811436            0.781018\n",
            "V-RNN               0.828841            0.787879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejors6dqaG6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}